#!/usr/bin/env python3
"""
ì•ˆì •ì ì¸ Prowler ë¶„ì„ MCP ì„œë²„ (HTML, CSV, JSON ì§€ì›)
"""

import json
import os
import re
from datetime import datetime
from pathlib import Path
from fastmcp import FastMCP
import argparse
from parser import *
from pprint import pp

# FastMCP ì•± ì´ˆê¸°í™”
mcp = FastMCP("Prowler Analyzer")

# ë¶„ì„í•  output í´ë” ê²½ë¡œ  
# OUTPUT_DIR = Path(r"C:\Users\ê¹€ì„œì—°\Desktop\whs-compler-mcp\output")
BASEDIR = Path(__file__).resolve().parent.parent
# print(BASEDIR.joinpath("./output"))
OUTPUT_DIR = BASEDIR.joinpath("prowler-reports")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

def parse_args():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±"""
    global OUTPUT_DIR
    p = argparse.ArgumentParser(description="Prowler MCP ì„œë²„ ì„¤ì •")
    p.add_argument(
        "--output-dir",
        type=str,
        default=str(OUTPUT_DIR),
        help="ë¶„ì„í•  Prowler ê²°ê³¼ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: ./output)",
    )

    p.add_argument(
        "--no-mcp-run",
        type=bool,
        default=False,
        help="MCP ì„œë²„ë¥¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ë””ë²„ê¹…ìš©)",
    )

    args = p.parse_args()

    # OUTPUT_DIR ì—…ë°ì´íŠ¸
    OUTPUT_DIR = Path(args.output_dir)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    return args

def get_latest_file():
    """ìµœì‹  íŒŒì¼ ì°¾ê¸°"""
    if not OUTPUT_DIR.exists():
        return None, f"Output ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {OUTPUT_DIR}"
    
    files = {f for f in OUTPUT_DIR.iterdir() if f.is_file()}
    files.discard(Path(OUTPUT_DIR).joinpath('.DS_Store'))
    if not files:
        return None, f"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {OUTPUT_DIR}"
    
    latest = max(files, key=lambda f: f.stat().st_mtime)
    return latest, None

def analyze_html_file(content, file_path):
    """HTML íŒŒì¼ ë¶„ì„ (ì•ˆì „í•œ ë²„ì „)"""
    try:
        # HTML íƒœê·¸ ì œê±°
        text_content = re.sub(r'<[^>]+>', '', content)
        text_content = re.sub(r'\s+', ' ', text_content).strip()
        
        # ê¸°ë³¸ ì •ë³´
        result = {

            "file_size": len(content),
            "text_length": len(text_content),
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê²€ìƒ‰
        keywords = {
            "PASS": len(re.findall(r'\bPASS\b', text_content, re.IGNORECASE)),
            "FAIL": len(re.findall(r'\bFAIL\b', text_content, re.IGNORECASE)),
            "CRITICAL": len(re.findall(r'\bCRITICAL\b', text_content, re.IGNORECASE)),
            "HIGH": len(re.findall(r'\bHIGH\b', text_content, re.IGNORECASE)),
            "MEDIUM": len(re.findall(r'\bMEDIUM\b', text_content, re.IGNORECASE)),
            "LOW": len(re.findall(r'\bLOW\b', text_content, re.IGNORECASE))
        }
        
        result["keyword_counts"] = keywords
        result["text_preview"] = text_content[:300] + "..." if len(text_content) > 300 else text_content
        
        return result
        
    except Exception as e:
        return {"error": f"HTML ë¶„ì„ ì˜¤ë¥˜: {str(e)}"}

def analyze_csv_file(content, file_path):
    """CSV íŒŒì¼ ë¶„ì„ (ì•ˆì „í•œ ë²„ì „)"""
    try:
        lines = [line.strip() for line in content.split('\n') if line.strip()]
        
        if not lines:
            return {"error": "ë¹ˆ CSV íŒŒì¼"}
        
        result = {
            "file_type": "Prowler CSV Results",
            "total_lines": len(lines),
            "header": lines[0] if lines else "",
            "data_rows": len(lines) - 1 if len(lines) > 1 else 0
        }
        
        # ìƒ˜í”Œ ë°ì´í„°
        if len(lines) > 1:
            result["sample_rows"] = lines[1:4]  # ì²˜ìŒ 3ê°œ ë°ì´í„° í–‰
        
        return result
        
    except Exception as e:
        return {"error": f"CSV ë¶„ì„ ì˜¤ë¥˜: {str(e)}"}

def analyze_json_file(content, file_path):
    """JSON íŒŒì¼ ë¶„ì„ (ì•ˆì „í•œ ë²„ì „)"""
    try:
        data = json.loads(content)
        
        result = {
            "file_type": "JSON Data",
            "data_type": type(data).__name__
        }
        
        if isinstance(data, list):
            result["item_count"] = len(data)
            if data and isinstance(data[0], dict):
                result["sample_keys"] = list(data[0].keys())[:5]
        elif isinstance(data, dict):
            result["keys"] = list(data.keys())[:10]
        
        return result
        
    except json.JSONDecodeError as e:
        return {"error": f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}"}
    except Exception as e:
        return {"error": f"JSON ë¶„ì„ ì˜¤ë¥˜: {str(e)}"}

@mcp.tool()
def get_latest_prowler_file() -> str:
    """output í´ë”ì—ì„œ ê°€ì¥ ìµœì‹  íŒŒì¼ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    latest_file, error = get_latest_file()
    
    if error:
        return f"âŒ {error}"
    
    file_stat = latest_file.stat()
    result = f"""
 **ìµœì‹  Prowler ê²°ê³¼ íŒŒì¼**

â€¢ **íŒŒì¼ëª…**: {latest_file.name}
â€¢ **ì „ì²´ ê²½ë¡œ**: {latest_file}
â€¢ **íŒŒì¼ í¬ê¸°**: {file_stat.st_size:,} bytes
â€¢ **ìˆ˜ì • ì¼ì‹œ**: {datetime.fromtimestamp(file_stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S')}
â€¢ **íŒŒì¼ í™•ì¥ì**: {latest_file.suffix}

 **ì„ íƒ ê·¼ê±°**: ì´ íŒŒì¼ì´ {OUTPUT_DIR} í´ë”ì—ì„œ ê°€ì¥ ìµœê·¼ì— ìˆ˜ì •ëœ íŒŒì¼ë¡œ, ìµœì‹  ë³´ì•ˆ ì ê²€ ê²°ê³¼ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
"""
    return result

@mcp.tool()
def analyze_prowler_results() -> str:
    """ìµœì‹  Prowler ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ë‚´ìš©ì„ í‘œì‹œí•©ë‹ˆë‹¤."""
    latest_file, error = get_latest_file()

    if error:
        return f"âŒ {error}"
    
    try:
        content = ""  # ì´ˆê¸°í™”
        # íŒŒì¼ ì½ê¸°
        with open(latest_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ë¶„ì„
        file_ext = latest_file.suffix.lower()

        if file_ext in ['.html', '.htm']:
            # analysis = analyze_html_file(content, latest_file)
            # analysis = parse_prowler_report_html_2(content, latest_file)
            analysis = parse_prowler_report_html(content, latest_file)
        elif file_ext == '.csv':
            analysis = analyze_csv_file(content, latest_file)
        elif file_ext in ['.json', '.json-asff']:
            analysis = analyze_json_file(content, latest_file)
            analysis = parse_prowler_report_asff_json(content)
        else:
            analysis = {
                "file_type": f"í…ìŠ¤íŠ¸ íŒŒì¼ ({file_ext})",
                "content_length": len(content),
                "line_count": len(content.splitlines()),
                "preview": content[:200] + "..." if len(content) > 200 else content
            }

        # ì˜¤ë¥˜ ì²´í¬
        if "error" in analysis:
            return f"âŒ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {analysis['error']}"

        # ë³´ê³ ì„œ ìƒì„±
        report = f"""
# ğŸ›¡ï¸ Prowler ê²°ê³¼ ë¶„ì„

##  íŒŒì¼ ì •ë³´
â€¢ **íŒŒì¼ëª…**: {latest_file.name}
â€¢ **í¬ê¸°**: {latest_file.stat().st_size:,} bytes
â€¢ **ìˆ˜ì •ì¼**: {datetime.fromtimestamp(latest_file.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')}
â€¢ **íŒŒì¼ ìœ í˜•**: {analysis.get('file_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}

##  ë¶„ì„ ê²°ê³¼
"""

        # HTML íŒŒì¼ ê²°ê³¼
        if analysis.get("file_type") == "Prowler HTML Report":
            keywords = analysis.get("keyword_counts", {})

            report += f"""
###  ë³´ì•ˆ ì ê²€ ìƒíƒœ (í‚¤ì›Œë“œ ê¸°ë°˜)
â€¢ âœ… **PASS**: {keywords.get('PASS', 0)}ê°œ ë°œê²¬
â€¢ âŒ **FAIL**: {keywords.get('FAIL', 0)}ê°œ ë°œê²¬

### ğŸš¨ ì‹¬ê°ë„ ë¶„í¬
â€¢ ğŸ”´ **CRITICAL**: {keywords.get('CRITICAL', 0)}ê°œ ì–¸ê¸‰
â€¢ ğŸŸ  **HIGH**: {keywords.get('HIGH', 0)}ê°œ ì–¸ê¸‰  
â€¢ ğŸŸ¡ **MEDIUM**: {keywords.get('MEDIUM', 0)}ê°œ ì–¸ê¸‰
â€¢ ğŸŸ¢ **LOW**: {keywords.get('LOW', 0)}ê°œ ì–¸ê¸‰

###  ë³´ê³ ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
```
{analysis.get('text_preview', 'ë‚´ìš© ì—†ìŒ')}
```
"""

        # CSV íŒŒì¼ ê²°ê³¼
        elif analysis.get("file_type") == "Prowler CSV Results":
            report += f"""
###  CSV ë°ì´í„° ì •ë³´
â€¢ **ì´ ë¼ì¸ ìˆ˜**: {analysis.get('total_lines', 0)}ê°œ
â€¢ **ë°ì´í„° í–‰ ìˆ˜**: {analysis.get('data_rows', 0)}ê°œ
â€¢ **í—¤ë”**: {analysis.get('header', 'ì—†ìŒ')[:100]}...

###  ìƒ˜í”Œ ë°ì´í„°
"""
            sample_rows = analysis.get('sample_rows', [])
            for i, row in enumerate(sample_rows, 1):
                report += f"{i}. {row[:100]}{'...' if len(row) > 100 else ''}\n"

        # JSON íŒŒì¼ ê²°ê³¼
        elif "JSON" in analysis.get("file_type", ""):
            report += f"""
###  JSON ë°ì´í„° ì •ë³´
â€¢ **ë°ì´í„° íƒ€ì…**: {analysis.get('data_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}
â€¢ **í•­ëª© ìˆ˜**: {analysis.get('item_count', 'N/A')}
â€¢ **ì£¼ìš” í‚¤**: {', '.join(analysis.get('sample_keys', []))}
â€¢ **ì ê²€ ìƒíƒœ**: {analysis.get('keyword_counts', {})}
"""

        # ê¸°íƒ€ íŒŒì¼
        else:
            report += f"""
###  íŒŒì¼ ì •ë³´
â€¢ **ë‚´ìš© ê¸¸ì´**: {analysis.get('content_length', 0)}ì
â€¢ **ë¼ì¸ ìˆ˜**: {analysis.get('line_count', 0)}ê°œ

###  ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
```
{analysis.get('preview', 'ë‚´ìš© ì—†ìŒ')}
```
"""

        # ì°¸ê³  ìë£Œ
        report += """
##  ë³´ì•ˆ ë¶„ì„ ì°¸ê³  ìë£Œ
â€¢ [Prowler ê³µì‹ ë¬¸ì„œ](https://docs.prowler.com/)
â€¢ [KISA-ISMS-P ì»´í”Œë¼ì´ì–¸ìŠ¤](https://hub.prowler.com/compliance/kisa_isms_p_2023_aws)
â€¢ [AWS ë³´ì•ˆ ëª¨ë²” ì‚¬ë¡€](https://aws.amazon.com/security/security-resources/)

##  ê¶Œì¥ì‚¬í•­
1. **ì‹¤íŒ¨ í•­ëª© ìš°ì„  ê²€í† **: FAIL ìƒíƒœì¸ í•­ëª©ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ í•´ê²°
2. **ì‹¬ê°ë„ë³„ ëŒ€ì‘**: CRITICAL > HIGH > MEDIUM > LOW ìˆœì„œë¡œ ì²˜ë¦¬
3. **ì •ê¸°ì  ì ê²€**: ì›” 1íšŒ ì´ìƒ ë³´ì•ˆ ì ê²€ ì‹¤ì‹œ
4. **ë¬¸ì„œí™”**: í•´ê²°ëœ í•­ëª©ë“¤ì— ëŒ€í•œ ê¸°ë¡ ìœ ì§€
"""

        return report

    except Exception as e:
        return f"âŒ íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

@mcp.tool()
def get_security_summary() -> str:
    """ë³´ì•ˆ ìƒíƒœ ê°„ë‹¨ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤."""
    latest_file, error = get_latest_file()
    
    if error:
        return f"âŒ {error}"
    
    try:
        with open(latest_file, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # ê°„ë‹¨í•œ í†µê³„
        pass_count = len(re.findall(r'\bPASS\b', content, re.IGNORECASE))
        fail_count = len(re.findall(r'\bFAIL\b', content, re.IGNORECASE))
        critical_count = len(re.findall(r'\bCRITICAL\b', content, re.IGNORECASE))
        
        total_checks = pass_count + fail_count
        pass_rate = (pass_count / total_checks * 100) if total_checks > 0 else 0
        
        # ë“±ê¸‰ ì‚°ì •
        if pass_rate >= 90:
            grade = "ğŸŸ¢ ìš°ìˆ˜ (Aë“±ê¸‰)"
        elif pass_rate >= 80:
            grade = "ğŸŸ¡ ì–‘í˜¸ (Bë“±ê¸‰)"
        elif pass_rate >= 70:
            grade = "ğŸŸ  ë³´í†µ (Cë“±ê¸‰)"
        else:
            grade = "ğŸ”´ ê°œì„  í•„ìš” (Dë“±ê¸‰)"
        
        summary = f"""
#  ë³´ì•ˆ ìƒíƒœ ìš”ì•½

##  ì „ì²´ í‰ê°€
**{grade}**

##  í•µì‹¬ ì§€í‘œ
â€¢ **í†µê³¼ìœ¨**: {pass_rate:.1f}%
â€¢ **í†µê³¼ í•­ëª©**: {pass_count}ê°œ
â€¢ **ì‹¤íŒ¨ í•­ëª©**: {fail_count}ê°œ
â€¢ **ì¹˜ëª…ì  ì´ìŠˆ**: {critical_count}ê°œ

##  ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­
{"ğŸ”´ ì¹˜ëª…ì  ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ í™•ì¸ í•„ìš”!" if critical_count > 0 else "âœ… ì¹˜ëª…ì  ì´ìŠˆê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

##  ê°œì„  ë°©í–¥
â€¢ í˜„ì¬ í†µê³¼ìœ¨ {pass_rate:.1f}%ì—ì„œ 90% ì´ìƒ ëª©í‘œ
â€¢ ì‹¤íŒ¨í•œ {fail_count}ê°œ í•­ëª©ì— ëŒ€í•œ ë‹¨ê³„ì  ê°œì„ 
â€¢ ì •ê¸°ì ì¸ ë³´ì•ˆ ì ê²€ìœ¼ë¡œ ì§€ì† ê´€ë¦¬

**íŒŒì¼**: {latest_file.name}
**ë¶„ì„ ì‹œì **: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        return summary
        
    except Exception as e:
        return f" ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

if __name__ == "__main__":
    print(" ì•ˆì •ì ì¸ Prowler MCP Server ì‹œì‘ ì¤‘...")
    print(f" ë¶„ì„ ëŒ€ìƒ í´ë”: {OUTPUT_DIR}")
    args = parse_args()
    if not args.no_mcp_run:
        print(" MCP ì„œë²„ ì‹¤í–‰ ì¤‘...")
        mcp.run()
    else:
        print(" MCP ì„œë²„ ì‹¤í–‰ì„ ê±´ë„ˆëœë‹ˆë‹¤. (ë””ë²„ê¹… ëª¨ë“œ)")
        with open(get_latest_file()[0], "r", encoding="utf-8") as f:
            # pp(analyze_html_file(f.read(), get_latest_file()[0]))
            # pp(parse_prowler_report_html(f.read()), indent=2, width=250)
            # pp(parse_prowler_report_html_2(f.read(), ), indent=2, width=250)
            # print(parse_prowler_report_asff_json(f.read()))
            # pp(analyze_json_file(f.read(), get_latest_file()[0]))
            # print(analyze_prowler_results())
            pass
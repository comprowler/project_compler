#!/usr/bin/env python3
"""
ì•ˆì •ì ì¸ Prowler ë¶„ì„ MCP ì„œë²„ (HTML, CSV, JSON ì§€ì›) + IaC YAML Writer
"""

import json
import os
import re
import yaml
import logging
from datetime import datetime
from idlelib.browser import file_open
from pathlib import Path
from typing import List, Annotated

import requests
from fastmcp import FastMCP
import argparse
from parser import *
from pprint import pp
from pydantic import BaseModel, Field, ValidationError

# Configure logging for YAML writer
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# FastMCP ì•± ì´ˆê¸°í™”
mcp = FastMCP("Prowler Analyzer with IaC YAML Writer")

# ë¶„ì„í•  output í´ë” ê²½ë¡œ  
# OUTPUT_DIR = Path(r"C:\Users\ê¹€ì„œì—°\Desktop\whs-compler-mcp\output")
BASEDIR = Path(__file__).resolve().parent.parent
# print(BASEDIR.joinpath("./output"))
OUTPUT_DIR = BASEDIR.joinpath("prowler-reports")
OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

# IaC YAML Writer ì„¤ì •
SCRIPT_DIR = Path(__file__).resolve().parent
PROJECT_ROOT = SCRIPT_DIR.parent  # í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë””ë ‰í† ë¦¬ (src í´ë”ì˜ ìƒìœ„)
IAC_OUTPUT_DIR = PROJECT_ROOT.joinpath("IaC_output")

# Create IaC_output directory if it doesn't exist
try:
    IAC_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    logger.info(f"IaC_output directory ensured at: {IAC_OUTPUT_DIR}")
except Exception as e:
    logger.critical(f"Failed to create IaC_output directory: {e}")
    raise

_iac_root_path = IAC_OUTPUT_DIR.resolve()
logger.info(f"IaC root directory set to: {_iac_root_path}")

# --- Pydantic Model Definition for YAML Writer ---
class YamlWriteParameters(BaseModel):
    """Parameters for writing a YAML file."""
    path: Annotated[str, Field(description="Path to the YAML file relative to IaC_output directory")]
    content: Annotated[str, Field(description="The YAML content as a string.")]
    create_dirs: Annotated[bool, Field(default=False, description="Whether to create parent directories if they do not exist.")]

# --- Utility Functions for YAML Writer ---
def _is_path_safe(root_path: str, target_path: str) -> bool:
    """
    Checks if the target_path is safely within the root_path.
    Prevents directory traversal attacks.
    """
    if not root_path:
        logger.error("Root path is not set, cannot check path safety.")
        return False
    try:
        abs_root = os.path.abspath(root_path)
        abs_target = os.path.abspath(os.path.join(root_path, target_path))
        is_safe = abs_target.startswith(abs_root)
        logger.debug(f"Path safety check: root='{abs_root}', target='{abs_target}', safe={is_safe}")
        return is_safe
    except Exception as e:
        logger.error(f"Error during path safety check: {e}")
        return False

def set_iac_root_directory(root_dir: str):
    """Set the IaC root directory."""
    global _iac_root_path
    try:
        if not os.path.isdir(root_dir):
            logger.info(f"Creating IaC root directory: {root_dir}")
            os.makedirs(root_dir, exist_ok=True)
        _iac_root_path = os.path.abspath(root_dir)
        logger.info(f"IaC root directory set to: {_iac_root_path}")
    except Exception as e:
        logger.critical(f"Failed to set IaC root directory '{root_dir}': {e}")
        raise

def parse_args():
    """ëª…ë ¹ì¤„ ì¸ì íŒŒì‹±"""
    global OUTPUT_DIR
    p = argparse.ArgumentParser(description="Prowler MCP ì„œë²„ ì„¤ì •")
    p.add_argument(
        "--output-dir",
        type=str,
        default=str(OUTPUT_DIR),
        help="ë¶„ì„í•  Prowler ê²°ê³¼ íŒŒì¼ì´ ìˆëŠ” ë””ë ‰í† ë¦¬ ê²½ë¡œ (ê¸°ë³¸ê°’: ./output)",
    )

    p.add_argument(
        "--no-mcp-run",
        type=bool,
        default=False,
        help="MCP ì„œë²„ë¥¼ ì‹¤í–‰í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤. (ë””ë²„ê¹…ìš©)",
    )

    args = p.parse_args()

    # OUTPUT_DIR ì—…ë°ì´íŠ¸
    OUTPUT_DIR = Path(args.output_dir)
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)
    return args

def get_latest_file():
    """ìµœì‹  íŒŒì¼ ì°¾ê¸°"""
    if not OUTPUT_DIR.exists():
        return None, f"Output ë””ë ‰í† ë¦¬ê°€ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {OUTPUT_DIR}"
    
    files = {f for f in OUTPUT_DIR.iterdir() if f.is_file()}
    files.discard(Path(OUTPUT_DIR).joinpath('.DS_Store'))
    if not files:
        return None, f"íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {OUTPUT_DIR}"
    
    latest = max(files, key=lambda f: f.stat().st_mtime)
    return latest, None

def analyze_html_file(content, file_path):
    """HTML íŒŒì¼ ë¶„ì„ (ì•ˆì „í•œ ë²„ì „)"""
    try:
        # HTML íƒœê·¸ ì œê±°
        text_content = re.sub(r'<[^>]+>', '', content)
        text_content = re.sub(r'\s+', ' ', text_content).strip()
        
        # ê¸°ë³¸ ì •ë³´
        result = {

            "file_size": len(content),
            "text_length": len(text_content),
        }
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê²€ìƒ‰
        keywords = {
            "PASS": len(re.findall(r'\bPASS\b', text_content, re.IGNORECASE)),
            "FAIL": len(re.findall(r'\bFAIL\b', text_content, re.IGNORECASE)),
            "CRITICAL": len(re.findall(r'\bCRITICAL\b', text_content, re.IGNORECASE)),
            "HIGH": len(re.findall(r'\bHIGH\b', text_content, re.IGNORECASE)),
            "MEDIUM": len(re.findall(r'\bMEDIUM\b', text_content, re.IGNORECASE)),
            "LOW": len(re.findall(r'\bLOW\b', text_content, re.IGNORECASE))
        }
        
        result["keyword_counts"] = keywords
        result["text_preview"] = text_content[:300] + "..." if len(text_content) > 300 else text_content
        
        return result
        
    except Exception as e:
        return {"error": f"HTML ë¶„ì„ ì˜¤ë¥˜: {str(e)}"}

def analyze_csv_file(content, file_path):
    """CSV íŒŒì¼ ë¶„ì„ (ì•ˆì „í•œ ë²„ì „)"""
    try:
        lines = [line.strip() for line in content.split('\n') if line.strip()]
        
        if not lines:
            return {"error": "ë¹ˆ CSV íŒŒì¼"}
        
        result = {
            "file_type": "Prowler CSV Results",
            "total_lines": len(lines),
            "header": lines[0] if lines else "",
            "data_rows": len(lines) - 1 if len(lines) > 1 else 0
        }
        
        # ìƒ˜í”Œ ë°ì´í„°
        if len(lines) > 1:
            result["sample_rows"] = lines[1:4]  # ì²˜ìŒ 3ê°œ ë°ì´í„° í–‰
        
        return result
        
    except Exception as e:
        return {"error": f"CSV ë¶„ì„ ì˜¤ë¥˜: {str(e)}"}

def analyze_json_file(content, file_path):
    """JSON íŒŒì¼ ë¶„ì„ (ì•ˆì „í•œ ë²„ì „)"""
    try:
        data = json.loads(content)
        
        result = {
            "file_type": "JSON Data",
            "data_type": type(data).__name__
        }
        
        if isinstance(data, list):
            result["item_count"] = len(data)
            if data and isinstance(data[0], dict):
                result["sample_keys"] = list(data[0].keys())[:5]
        elif isinstance(data, dict):
            result["keys"] = list(data.keys())[:10]
        
        return result
        
    except json.JSONDecodeError as e:
        return {"error": f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}"}
    except Exception as e:
        return {"error": f"JSON ë¶„ì„ ì˜¤ë¥˜: {str(e)}"}

# ========== PROWLER ANALYSIS TOOLS ==========

@mcp.tool()
def get_latest_prowler_file() -> str:
    """output í´ë”ì—ì„œ ê°€ì¥ ìµœì‹  íŒŒì¼ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤."""
    latest_file, error = get_latest_file()
    
    if error:
        return f"âŒ {error}"
    
    file_stat = latest_file.stat()
    result = f"""
 **ìµœì‹  Prowler ê²°ê³¼ íŒŒì¼**

â€¢ **íŒŒì¼ëª…**: {latest_file.name}
â€¢ **ì „ì²´ ê²½ë¡œ**: {latest_file}
â€¢ **íŒŒì¼ í¬ê¸°**: {file_stat.st_size:,} bytes
â€¢ **ìˆ˜ì • ì¼ì‹œ**: {datetime.fromtimestamp(file_stat.st_mtime).strftime('%Y-%m-%d %H:%M:%S')}
â€¢ **íŒŒì¼ í™•ì¥ì**: {latest_file.suffix}

 **ì„ íƒ ê·¼ê±°**: ì´ íŒŒì¼ì´ {OUTPUT_DIR} í´ë”ì—ì„œ ê°€ì¥ ìµœê·¼ì— ìˆ˜ì •ëœ íŒŒì¼ë¡œ, ìµœì‹  ë³´ì•ˆ ì ê²€ ê²°ê³¼ë¥¼ í¬í•¨í•˜ê³  ìˆìŠµë‹ˆë‹¤.
"""
    return result

@mcp.tool()
def analyze_prowler_results(file_path, file_preview_length:int=500) -> str:
    """Prowler ê²°ê³¼ íŒŒì¼ì„ ë¶„ì„í•˜ê³  ë‚´ìš©ì„ í‘œì‹œí•©ë‹ˆë‹¤.
    :param file_path: ë¶„ì„í•  Prowler ê²°ê³¼ íŒŒì¼ ê²½ë¡œ
    :param file_preview_length: ë¯¸ë¦¬ë³´ê¸° í…ìŠ¤íŠ¸ ê¸¸ì´ (ê¸°ë³¸ê°’: 500ì)
    :return: ë¶„ì„ ê²°ê³¼ ë¬¸ìì—´
    """
    # """ìµœì‹  Prowler ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  ë‚´ìš©ì„ í‘œì‹œí•©ë‹ˆë‹¤."""
    # latest_file, error = get_latest_file()
    # if error:
    #     return f"âŒ {error}"
    file_path = Path(file_path)
    try:
        # íŒŒì¼ ì½ê¸°
        with open(file_path, 'r', encoding='utf-8') as file:
            file_content = file.read()
        
        # íŒŒì¼ í™•ì¥ìì— ë”°ë¥¸ ë¶„ì„
        file_ext = file_path.suffix.lower()

        if file_ext in ['.html', '.htm']:
            # analysis = analyze_html_file(content, latest_file)
            # analysis = parse_prowler_report_html_2(content, latest_file)
            analysis = parse_prowler_report_html(file_content, file_preview_length)
        elif file_ext == '.csv':
            analysis = analyze_csv_file(file_content, file_path)
        elif file_ext in ['.json', '.json-asff']:
            # analysis = analyze_json_file(file_content, file_path)
            analysis = parse_prowler_report_asff_json(file_content)
        else:
            analysis = {
                "file_type": f"í…ìŠ¤íŠ¸ íŒŒì¼ ({file_ext})",
                "content_length": len(file_content),
                "line_count": len(file_content.splitlines()),
                "preview": file_content[:200] + "..." if len(file_content) > 200 else file_content
            }

        # ì˜¤ë¥˜ ì²´í¬
        if "error" in analysis:
            return f"âŒ íŒŒì¼ ë¶„ì„ ì‹¤íŒ¨: {analysis['error']}"

        # ë³´ê³ ì„œ ìƒì„±
        report = f"""
# ğŸ›¡ï¸ Prowler ê²°ê³¼ ë¶„ì„

##  íŒŒì¼ ì •ë³´
â€¢ **íŒŒì¼ëª…**: {file_path.name}
â€¢ **í¬ê¸°**: {file_path.stat().st_size:,} bytes
â€¢ **ìˆ˜ì •ì¼**: {datetime.fromtimestamp(file_path.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')}
â€¢ **íŒŒì¼ ìœ í˜•**: {analysis.get('file_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}

##  ë¶„ì„ ê²°ê³¼
"""

        # HTML íŒŒì¼ ê²°ê³¼
        if analysis.get("file_type") == "Prowler HTML Report":
            keywords = analysis.get("keyword_counts", {})

            report += \
f"""###  ë³´ì•ˆ ì ê²€ ìƒíƒœ (í‚¤ì›Œë“œ ê¸°ë°˜)
â€¢ âœ… **PASS**: {keywords.get('PASS', 0)}ê°œ ë°œê²¬
â€¢ âŒ **FAIL**: {keywords.get('FAIL', 0)}ê°œ ë°œê²¬

### ğŸš¨ ì‹¬ê°ë„ ë¶„í¬
â€¢ ğŸ”´ **CRITICAL**: {keywords.get('CRITICAL', 0)}ê°œ ì–¸ê¸‰
â€¢ ğŸŸ  **HIGH**: {keywords.get('HIGH', 0)}ê°œ ì–¸ê¸‰  
â€¢ ğŸŸ¡ **MEDIUM**: {keywords.get('MEDIUM', 0)}ê°œ ì–¸ê¸‰
â€¢ ğŸŸ¢ **LOW**: {keywords.get('LOW', 0)}ê°œ ì–¸ê¸‰

###  ë³´ê³ ì„œ ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
```
{analysis.get('text_preview', 'ë‚´ìš© ì—†ìŒ')}
```
"""

        # CSV íŒŒì¼ ê²°ê³¼
        elif analysis.get("file_type") == "Prowler CSV Results":
            report += f"""
###  CSV ë°ì´í„° ì •ë³´
â€¢ **ì´ ë¼ì¸ ìˆ˜**: {analysis.get('total_lines', 0)}ê°œ
â€¢ **ë°ì´í„° í–‰ ìˆ˜**: {analysis.get('data_rows', 0)}ê°œ
â€¢ **í—¤ë”**: {analysis.get('header', 'ì—†ìŒ')[:100]}...

###  ìƒ˜í”Œ ë°ì´í„°
"""
            sample_rows = analysis.get('sample_rows', [])
            for i, row in enumerate(sample_rows, 1):
                report += f"{i}. {row[:100]}{'...' if len(row) > 100 else ''}\n"

        # JSON íŒŒì¼ ê²°ê³¼
        elif "JSON" in analysis.get("file_type", ""):
            report += f"""
###  JSON ë°ì´í„° ì •ë³´
â€¢ **ë°ì´í„° íƒ€ì…**: {analysis.get('data_type', 'ì•Œ ìˆ˜ ì—†ìŒ')}
â€¢ **í•­ëª© ìˆ˜**: {analysis.get('item_count', 'N/A')}
â€¢ **ì£¼ìš” í‚¤**: {', '.join(analysis.get('sample_keys', []))}
â€¢ **ì ê²€ ìƒíƒœ**: {analysis.get('keyword_counts', {})}
"""

        # ê¸°íƒ€ íŒŒì¼
        else:
            report += f"""
###  íŒŒì¼ ì •ë³´
â€¢ **ë‚´ìš© ê¸¸ì´**: {analysis.get('content_length', 0)}ì
â€¢ **ë¼ì¸ ìˆ˜**: {analysis.get('line_count', 0)}ê°œ

###  ë‚´ìš© ë¯¸ë¦¬ë³´ê¸°
```
{analysis.get('preview', 'ë‚´ìš© ì—†ìŒ')}
```
"""

        # ì°¸ê³  ìë£Œ
        report += """
##  ë³´ì•ˆ ë¶„ì„ ì°¸ê³  ìë£Œ
â€¢ [Prowler ê³µì‹ ë¬¸ì„œ](https://docs.prowler.com/)
â€¢ [KISA-ISMS-P ì»´í”Œë¼ì´ì–¸ìŠ¤](https://hub.prowler.com/compliance/kisa_isms_p_2023_aws)
â€¢ [AWS ë³´ì•ˆ ëª¨ë²” ì‚¬ë¡€](https://aws.amazon.com/security/security-resources/)

##  ê¶Œì¥ì‚¬í•­
1. **ì‹¤íŒ¨ í•­ëª© ìš°ì„  ê²€í† **: FAIL ìƒíƒœì¸ í•­ëª©ë“¤ì„ ìš°ì„ ì ìœ¼ë¡œ í•´ê²°
2. **ì‹¬ê°ë„ë³„ ëŒ€ì‘**: CRITICAL > HIGH > MEDIUM > LOW ìˆœì„œë¡œ ì²˜ë¦¬
3. **ì •ê¸°ì  ì ê²€**: ì›” 1íšŒ ì´ìƒ ë³´ì•ˆ ì ê²€ ì‹¤ì‹œ
4. **ë¬¸ì„œí™”**: í•´ê²°ëœ í•­ëª©ë“¤ì— ëŒ€í•œ ê¸°ë¡ ìœ ì§€
"""

        return report

    except Exception as e:
        return f"âŒ íŒŒì¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"

@mcp.tool()
def get_security_summary(file_path) -> str:
    """ë³´ì•ˆ ìƒíƒœ ê°„ë‹¨ ìš”ì•½ì„ ì œê³µí•©ë‹ˆë‹¤."""
    # latest_file, error = get_latest_file()
    #
    # if error:
    #     return f"âŒ {error}"
    file_path = Path(file_path)
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            file_content = f.read()
        
        # ê°„ë‹¨í•œ í†µê³„
        pass_count = len(re.findall(r'\bPASS\b', file_content, re.IGNORECASE))
        fail_count = len(re.findall(r'\bFAIL\b', file_content, re.IGNORECASE))
        critical_count = len(re.findall(r'\bCRITICAL\b', file_content, re.IGNORECASE))
        
        total_checks = pass_count + fail_count
        pass_rate = (pass_count / total_checks * 100) if total_checks > 0 else 0
        
        # ë“±ê¸‰ ì‚°ì •
        if pass_rate >= 90:
            grade = "ğŸŸ¢ ìš°ìˆ˜ (Aë“±ê¸‰)"
        elif pass_rate >= 80:
            grade = "ğŸŸ¡ ì–‘í˜¸ (Bë“±ê¸‰)"
        elif pass_rate >= 70:
            grade = "ğŸŸ  ë³´í†µ (Cë“±ê¸‰)"
        else:
            grade = "ğŸ”´ ê°œì„  í•„ìš” (Dë“±ê¸‰)"
        
        summary = f"""
#  ë³´ì•ˆ ìƒíƒœ ìš”ì•½

##  ì „ì²´ í‰ê°€
**{grade}**

##  í•µì‹¬ ì§€í‘œ
â€¢ **í†µê³¼ìœ¨**: {pass_rate:.1f}%
â€¢ **í†µê³¼ í•­ëª©**: {pass_count}ê°œ
â€¢ **ì‹¤íŒ¨ í•­ëª©**: {fail_count}ê°œ
â€¢ **ì¹˜ëª…ì  ì´ìŠˆ**: {critical_count}ê°œ

##  ì¦‰ì‹œ ì¡°ì¹˜ì‚¬í•­
{"ğŸ”´ ì¹˜ëª…ì  ì´ìŠˆê°€ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤. ì¦‰ì‹œ í™•ì¸ í•„ìš”!" if critical_count > 0 else "âœ… ì¹˜ëª…ì  ì´ìŠˆê°€ ë°œê²¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

##  ê°œì„  ë°©í–¥
â€¢ í˜„ì¬ í†µê³¼ìœ¨ {pass_rate:.1f}%ì—ì„œ 90% ì´ìƒ ëª©í‘œ
â€¢ ì‹¤íŒ¨í•œ {fail_count}ê°œ í•­ëª©ì— ëŒ€í•œ ë‹¨ê³„ì  ê°œì„ 
â€¢ ì •ê¸°ì ì¸ ë³´ì•ˆ ì ê²€ìœ¼ë¡œ ì§€ì† ê´€ë¦¬

**íŒŒì¼**: {file_path.name}
**ë¶„ì„ ì‹œì **: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
        
        return summary
        
    except Exception as e:
        return f" ìš”ì•½ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

@mcp.tool()
def get_prowler_reports_list() -> List[tuple]:
    """Prowler ê²°ê³¼ íŒŒì¼ ëª©ë¡ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    :param
        None
    :return:
        list[]: Prowler ê²°ê³¼ íŒŒì¼ ëª©ë¡
    """
    try:
        files = [f for f in OUTPUT_DIR.iterdir() if f.is_file()]
        if not files:
            return []

        report_list = []
        for file in sorted(files, key=lambda f: f.stat().st_mtime, reverse=True):
            file_stat = file.stat()
            if file.name == '.DS_Store':
                continue
            report_list.append((file.name, file, f'{round(file_stat.st_size/1024):,} KB', file.suffix))
        return report_list
    except Exception as e:
        return [(f"âŒ íŒŒì¼ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {str(e)}",)]

@mcp.tool()
def get_file_content(file_path: str) -> str:
    """íŒŒì¼ ë‚´ìš©ì„ ê°€ì ¸ì˜µë‹ˆë‹¤.
    :param file_path: íŒŒì¼ ê²½ë¡œ
    :return: íŒŒì¼ ë‚´ìš©
    """
    try:
        file_path = Path(file_path)
        if not file_path.exists():
            return f"âŒ íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {file_path}"

        with open(file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        # íŒŒì¼ ë‚´ìš©ì´ 2MBë¥¼ ì´ˆê³¼í•˜ë©´ ë¯¸ë¦¬ë³´ê¸°ë§Œ ì œê³µ
        if len(content) > 2 * 1024 * 1024:  # 2MB
            return f"ğŸ“„ íŒŒì¼ ë‚´ìš©ì´ ë„ˆë¬´ ê¹ë‹ˆë‹¤. ë¯¸ë¦¬ë³´ê¸°:\n{content[:2000]}..."
        return content

    except Exception as e:
        return f"âŒ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {str(e)}"


@mcp.tool()
def get_cloud_custodian_aws_resource_reference_html(resource_name: str) -> str:
    """
    Generate HTML reference for a given AWS resource name.
    :param resource_name: str - Name of the AWS resource ("s3", "iam-role", "iam-user", "security-group", "cloudtrail", "ec2", "rds", "vpc", "lambda", "kms")
    :return: HTML string with the resource reference.
    """
    url = f"https://cloudcustodian.io/docs/aws/resources/{resource_name}.html"
    if resource_name not in {
        "s3", "iam-role", "iam-user", "security-group", "cloudtrail",
        "ec2", "rds", "vpc", "lambda", "kms"
    }:
        return f"{resource_name} is not a valid resource name., please use one of the following: s3, iam-role, iam-user, security-group, cloudtrail, ec2, rds, vpc, lambda, kms."
    try:
        response = requests.get(url)
        response.raise_for_status()  # Raise an error for bad responses
        return response.text
    except requests.RequestException as e:
        print(f"Error fetching resource reference for {resource_name}: {e}")
        return f"{resource_name.capitalize()} (reference not available)"

# ========== IAC YAML WRITER TOOLS ==========

@mcp.tool()
def write_yaml_file(
    path: Annotated[str, Field(description="Path to the YAML file to write. Must be relative to the IaC_output directory.")],
    content: Annotated[str, Field(description="The YAML content as a string.")],
    create_dirs: Annotated[bool, Field(default=False, description="Whether to create parent directories if they do not exist.")] = False
) -> str:
    """Write YAML content to the specified file in the IaC_output directory."""
    logger.info(f"Writing YAML file: path='{path}', create_dirs={create_dirs}")
    
    # Validate parameters using Pydantic
    try:
        params = YamlWriteParameters(path=path, content=content, create_dirs=create_dirs)
        logger.info(f"Parameters validated: path='{params.path}', create_dirs={params.create_dirs}")
    except ValidationError as e:
        error_msg = f"Invalid parameters for write-yaml-file: {e.errors()}"
        logger.error(error_msg)
        raise ValueError(error_msg)

    # Check path safety
    if not _is_path_safe(str(_iac_root_path), params.path):
        error_msg = f"Unsafe path '{params.path}' outside root directory '{_iac_root_path}'"
        logger.error(error_msg)
        raise ValueError(error_msg)

    full_file_path = _iac_root_path / params.path
    directory = full_file_path.parent
    logger.info(f"Full target path: '{full_file_path}', Directory: '{directory}'")

    try:
        # Create directories if needed
        if params.create_dirs:
            if not directory.exists():
                logger.info(f"Creating parent directories for '{directory}'")
                directory.mkdir(parents=True, exist_ok=True)
            else:
                logger.debug(f"Directory '{directory}' already exists")
        elif not directory.exists():
            error_msg = f"Parent directory '{directory}' does not exist and create_dirs is false"
            logger.error(error_msg)
            raise ValueError(error_msg)

        # Validate YAML content
        try:
            yaml.safe_load(params.content)
            logger.info("YAML content is valid")
        except yaml.YAMLError as e:
            error_msg = f"Invalid YAML content: {e}"
            logger.error(error_msg)
            raise ValueError(error_msg)

        # Write the file
        logger.info(f"Writing to file: '{full_file_path}'")
        with open(full_file_path, 'w', encoding='utf-8') as f:
            f.write(params.content)
        
        success_msg = f"Successfully wrote YAML to '{params.path}' in IaC_output directory: {full_file_path}"
        logger.info(success_msg)
        return success_msg

    except IOError as e:
        error_msg = f"Failed to write file '{params.path}': {e}"
        logger.error(error_msg)
        raise IOError(error_msg)
    except Exception as e:
        error_msg = f"Unexpected error during file operation: {e}"
        logger.critical(error_msg, exc_info=True)
        raise Exception(error_msg)

@mcp.tool()
def create_iac_directory(
    directory_path: Annotated[str, Field(description="Directory path to create relative to IaC_output directory")]
) -> str:
    """Create a directory in the IaC_output folder."""
    logger.info(f"Creating directory: {directory_path}")
    
    # Check path safety
    if not _is_path_safe(str(_iac_root_path), directory_path):
        error_msg = f"Unsafe path '{directory_path}' outside root directory '{_iac_root_path}'"
        logger.error(error_msg)
        return error_msg

    full_dir_path = _iac_root_path / directory_path
    
    try:
        full_dir_path.mkdir(parents=True, exist_ok=True)
        success_msg = f"Successfully created directory: {full_dir_path}"
        logger.info(success_msg)
        return success_msg
    except Exception as e:
        error_msg = f"Failed to create directory '{directory_path}': {e}"
        logger.error(error_msg)
        return error_msg

@mcp.tool()
def list_iac_files() -> str:
    """List all files in the IaC_output directory."""
    try:
        if not _iac_root_path.exists():
            return f"IaC_output directory does not exist: {_iac_root_path}"
        
        files = []
        for item in _iac_root_path.rglob("*"):
            if item.is_file():
                relative_path = item.relative_to(_iac_root_path)
                file_size = item.stat().st_size
                modified_time = datetime.fromtimestamp(item.stat().st_mtime).strftime('%Y-%m-%d %H:%M:%S')
                files.append(f"ğŸ“„ {relative_path} ({file_size:,} bytes, modified: {modified_time})")
        
        if not files:
            return f"No files found in IaC_output directory: {_iac_root_path}"
        
        return f"""
# ğŸ“ IaC Output Directory Contents

**Location**: {_iac_root_path}

## Files:
""" + "\n".join(files)

    except Exception as e:
        error_msg = f"Failed to list IaC files: {e}"
        logger.error(error_msg)
        return error_msg

@mcp.tool()
def get_iac_file_content(
    file_path: Annotated[str, Field(description="Path to the file relative to IaC_output directory")]
) -> str:
    """Get the content of a file in the IaC_output directory."""
    # Check path safety
    if not _is_path_safe(str(_iac_root_path), file_path):
        error_msg = f"Unsafe path '{file_path}' outside root directory '{_iac_root_path}'"
        logger.error(error_msg)
        return error_msg

    full_file_path = _iac_root_path / file_path
    
    try:
        if not full_file_path.exists():
            return f"File does not exist: {file_path}"
        
        if not full_file_path.is_file():
            return f"Path is not a file: {file_path}"
        
        with open(full_file_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        return f"""
# ğŸ“„ File Content: {file_path}

**Full Path**: {full_file_path}
**Size**: {len(content):,} characters

## Content:
```yaml
{content}
```
"""
    
    except Exception as e:
        error_msg = f"Failed to read file '{file_path}': {e}"
        logger.error(error_msg)
        return error_msg


if __name__ == "__main__":
    print("Prowler MCP Server with IaC YAML Writer ì‹œì‘ ì¤‘...")
    print(f"ğŸ“Š Prowler ë¶„ì„ ëŒ€ìƒ í´ë”: {OUTPUT_DIR}")
    print(f"ğŸ“ IaC YAML ì¶œë ¥ í´ë”: {IAC_OUTPUT_DIR}")
    args = parse_args()
    if not args.no_mcp_run:
        print("ğŸš€ MCP ì„œë²„ ì‹¤í–‰ ì¤‘...")
        mcp.run()
    else:
        print("ğŸ”§ MCP ì„œë²„ ì‹¤í–‰ì„ ê±´ë„ˆëœë‹ˆë‹¤. (ë””ë²„ê¹… ëª¨ë“œ)")
        with open(get_latest_file()[0], "r", encoding="utf-8") as f:
            pass
            # print(get_prowler_reports_list())